{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Sine and Tangent Series Classification - Multiclass\n",
    "\n",
    "Here, we'll use LSTM to classify the Sine series and Tangent series, considering them as the time-series.\n",
    "\n",
    "**Step 1 : Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 : Loading or Formulating the dataset**\n",
    "\n",
    "Here we need to create the random series of both Sine and Tangent. **Sine** would be labeld as **0** and **Tangent** series would be **1**.\n",
    "\n",
    "The structure of the dataset would be\n",
    "\n",
    "| X   | y   |\n",
    "| :---: | :--:|\n",
    "| $[sin(a), sin(a+1), sin(a+2)..., sin(a+n)]$ | 0 |\n",
    "| $[tan(a), tan(a+1), tan(a+2)..., tan(a+n)]$ | 1 |\n",
    "| $[sin(b), sin(b+1), sin(b+2)..., sin(b+n)]$ | 0 |\n",
    "| $[tan(b), tan(b+1), tan(b+2)..., tan(b+n)]$ | 1 |\n",
    "| $... ... ... ... ...$  | ... |\n",
    "| $[sin(z), sin(z+1), sin(z+2)..., sin(z+n)]$ | 0 |\n",
    "| $[tan(z), tan(z+1), tan(z+2)..., tan(z+n)]$ | 1 |\n",
    "\n",
    "$a ... z$ are the random number between $0 - 100.$<br/>\n",
    "$n$ is the maximum data points we need. Here we choose it to be 400.<br/>\n",
    "The rows in the dataset let's say would be $1000$. $500$ for $sin(x)$ and $500$ for $tan(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_series = []\n",
    "\n",
    "for _ in range(0,1000):\n",
    "\n",
    "    rn = np.random.randint(0,100)\n",
    "\n",
    "    series_1 = []\n",
    "    series_2 = []    \n",
    "\n",
    "    for i in range(rn,rn+400):\n",
    "        series_1.append(np.sin(i) + 1)\n",
    "        series_2.append(np.abs(np.tan(i)))\n",
    "\n",
    "    main_series.append((series_1,0))\n",
    "    main_series.append((series_2,1))\n",
    "\n",
    "df = pd.DataFrame(main_series, columns=['X','y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0007931658136463016, 0.4936343588902412, 1....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[25.092534979676547, 0.5872139151569291, 0.506...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.2608193033507772, 1.167355700302807, 1.9200...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0975097786622852, 0.16974975208268753, 2.34...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.37011200572554614, 1.313228782433085, 1.968...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  y\n",
       "0  [0.0007931658136463016, 0.4936343588902412, 1....  0\n",
       "1  [25.092534979676547, 0.5872139151569291, 0.506...  1\n",
       "2  [0.2608193033507772, 1.167355700302807, 1.9200...  0\n",
       "3  [1.0975097786622852, 0.16974975208268753, 2.34...  1\n",
       "4  [0.37011200572554614, 1.313228782433085, 1.968...  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['X'], df['y'], test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 : Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from this would be series, so converting the values to list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(X_train)\n",
    "X_test = list(X_test)\n",
    "y_train = list(y_train)\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the values to the Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(X_train).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 : Modelling**\n",
    "\n",
    "This part is most important so let's understand this properly.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Network Initialization\n",
    "\n",
    "**Input-Output**\n",
    "\n",
    "Let's talk about input and output of the model first. <br/>\n",
    "\n",
    "From **Step : 2** we have that the dataset is of $1000$ rows with each row of series length $400$. Therefore, the `self.input_layer_size` will be $400$.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Hidden Layer**\n",
    "\n",
    "So the hidden layer could have any number of value. We would need to tweak this value to see when the model performs the best. For now, let's keep this value as $200$.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**LSTM Layer**\n",
    "\n",
    "As per the parameters defined above the *LSTM* layer would be like :\n",
    "\n",
    "`self.lstm = nn.LSTM(self.input_layer_size, self.hidden_layer_size)` or ` self.lstm = nn.LSTM(400, 200)`\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Fully Connected Layer**\n",
    "\n",
    "Now as the output of the *LSTM* layer is $200$, the input of the *Fully Conected* layer, which comes after the *LSTM* layer, should have to be $200$ as well. That is `self.hidden_layer_size` would be $200$.\n",
    "\n",
    "The output of the *Fully Conected* layer depends upon the number of classes we have in the dataset. For now we have 2 classes, $0$ and $1$. This problem therefore is a *\"Multiclass Classification\"* problem. This would require the output of the network to be equal to the number of classes we have, since here we have two classes *sine series* and *tangent Series*, the value of output would be $2$. That is `self.output_layer_size` would be $2$\n",
    "\n",
    "This can be achieved by setting the output of the *Fully Conected* as $2$.\n",
    "\n",
    "So, as per the parameters defined above the *Fully Conected* layer would be like : \n",
    "\n",
    "`self.fc = nn.Linear(self.hidden_layer_size, self.output_layer_size)` or `self.fc = nn.Linear(200, 2)`\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Hidden Cell**\n",
    "\n",
    "We know that the *LSTM* cell have two more inputs apart from the data. They are called Hidden State Tensor $h_t$ and Cell State Tensor $c_t$. The dimensions of both $h_t$ and $c_t$ are same. \n",
    "\n",
    "Since the network need these as inputs so we need to pass them to the *LSTM* cell as well, although the network doesn't care what the initial values/states of $h_t$ and $c_t$ are, so we initialize them with $0$ Tensor.\n",
    "\n",
    "Dimension of both $h_t$ and $c_t$ would be : (*number of LSTM layers*, *batch size*, *hidden layer size*)\n",
    "\n",
    "In our case we have :\n",
    "\n",
    "*number of LSTM layers* : $1$<br/>\n",
    "*batch size* : $1$<br/>\n",
    "*hidden layer size* : $200$\n",
    "\n",
    "So, the Tensor value for $h_t$ would be = `torch.zeros(1,1,self.hidden_layer_size)`<br/>\n",
    "the Tensor value for $c_t$ would be = `torch.zeros(1,1,self.hidden_layer_size)`\n",
    "\n",
    "Here, `self.hidden_cell` is a touple having both `(h_t, c_t)`\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Softmax Activation**\n",
    "\n",
    "Since this is a *Multiclass Classification Problem* we would need to keep the output of the network between euqual to the number of classes we're classifying. Like if we're are classifying into 2 classes we have the output like : \n",
    "\n",
    "`[0.45, 0.55]`\n",
    "\n",
    "Each value would represent the probability of being classified as the class. So *Class 0* has the probability of $0.45$ and *Class 1* has the probability of $0.55$ . Since the probabilty of class $1$ is highest, the classificaion of the input would be class $1$.\n",
    "\n",
    "The *Softmax Activation Function* on the output is already there inside the `CrossEntropyLoss` so we do not need to explicitly use it anywhere.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Forward Function\n",
    "\n",
    "This is where we'll use the above definations of the layers. This *Forward* function is the one which takes the input during the training of the phase or the prediction phase of the model. In our case, the input to this function `input_seq` is basically one of the following series :\n",
    "\n",
    "$[sin(a), sin(a+1), sin(a+2)..., sin(a+n)]$  for $n=400$\n",
    "\n",
    "$[tan(a), tan(a+1), tan(a+2)..., tan(a+n)]$ for $n=400$\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**LSTM Initialization**\n",
    "\n",
    "Since the incomming series is of dimension [1 x 400] or [400] which is a single dimensional tensor, we would need to convert it into 3 dimensional tensor i.e. [1,1,400]. This could be done as follows :\n",
    "\n",
    "`input_seq.view(1 ,1, -1)`\n",
    "\n",
    "This converted series will then have to be passed to *LSTM* layer's input. Also, we discussed above that the *LSTM Layer* also takes the hidden and cell state $h_t$ and $c_t$ as input. We would need to pass it as well during the layer's initialization along with the 3 dimensional series. This is done as follows:\n",
    "\n",
    "`self.lstm(input_seq.view(1 ,1, -1), self.hidden_cell)`\n",
    "\n",
    "Here, the first parameter and the second parameter we know that we should keep them as $1$ and since we don't want to do extra calculation to see what could be the value of the third dimension, we write `-1`. This will automatically calculate the value and assign it to the parameter.\n",
    "\n",
    "The *LSTM Layer* will output two values after the completion, first would be the output data $\\hat{y}$ (`lstm_out`) and the hidden states ($h_t$, $c_t$) (`self.hidden_cell`). **The value of** (`self.hidden_cell`) **is to be passed in the next epoch and this is very important to make sure that this happenes.** So, we've assigned the value of the hidden state ($h_t$, $c_t$) comming back from the *LSTM Layer* to the same variable `self.hidden_cell` so that it will go back into the *LSTM Layer* on the next epoch execution.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Fully Connected Layer Initialization**\n",
    "\n",
    "The output `lstm_out` from the *LSTM Layer* which came along with the the hidden states ($h_t$, $c_t$) (`self.hidden_cell`) will be passed to the *Fully Connected Layer*. \n",
    "\n",
    "The input to the *Fully Connected Layer* should be a *vector*. So we would need to convert the dimension of `lstm_out` to a single dimensional vector. This can be done using the `view()` function. We pass in this function `view(1,-1)`. Here first parameter is the *number of rows* and second is *number of columns* (for a 2D setting we are saying this). We know that *number of rows* should be $1$ so we pass it as $1$. And since we don't want to do extra calculation to see what could be the value of *number of columns*, we write `-1`. This will automatically calculate the value and assign it to the columns.\n",
    "\n",
    "The *output* of the *Fully Connected Layer* would be a single value as it has output dimension $1$.\n",
    "\n",
    "`lstm_out, self.hidden_cell = self.lstm(input_seq.view(1 ,1, -1), self.hidden_cell)`\n",
    "\n",
    "<hr/>\n",
    "\n",
    "**Softmax Activation**\n",
    "\n",
    "The *output* of the *Fully Connected Layer* should be between give the probability of each class for being classified as the class for the input provided. The *Softmax Activation Function* on the output is already there inside the `CrossEntropyLoss` so we do not need to explicitly use it anywhere.\n",
    "\n",
    "***On a side-note :*** \n",
    "*The output from the ***fully connected layer*** (which is an array of value count equals to that of class count) is not the probabilites of the classes unless we pass it through softmax, so what we get here is usually a float value for a class, the higher this value for a class the higher the probability of the class to be the final class. So we take the index of the max of this array i.e. `argmax(array)` which will give the final class.*\n",
    "\n",
    "<hr/>\n",
    "\n",
    "Finally, the last value of the array `predictions` would be the return value of the network. This means that the network has classified the given `input_seq` as whatever `predictions[-1]` contains. `predictions` is a tensor of size $[1, 1]$ and have the values like $[[0.34]]$, so to reshape the Tensor to $[0.34]$, we take the last item of it, i.e. $[-1]$. This value will then be matched with the *True value* and an error will be calculated, which then will be use to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModule(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LSTMModule, self).__init__()\n",
    "\n",
    "        self.input_layer_size = 400\n",
    "        self.hidden_layer_size = 200\n",
    "        self.output_layer_size = 2\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_layer_size, self.hidden_layer_size)\n",
    "        self.fc = nn.Linear(self.hidden_layer_size, self.output_layer_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size).to(device), torch.zeros(1,1,self.hidden_layer_size).to(device))\n",
    "\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(1 ,1, -1), self.hidden_cell)\n",
    "        predictions = self.fc(lstm_out.view(1, -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Loss function and Optimizer for the model training. \n",
    "\n",
    "***Loss Function*** -> Cross Entropy Loss since this is a Multiclass classification problem<br/>\n",
    "***Optimizer*** -> ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModule().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModule(\n",
      "  (lstm): LSTM(400, 200)\n",
      "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5 : Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n",
      "training loss: 0.3514, acc 0.8469 \n",
      "validation loss: 0.6686, validation acc 0.7025 \n",
      "____________________\n",
      "Epoch :  2\n",
      "training loss: 0.1147, acc 0.9775 \n",
      "validation loss: 0.7805, validation acc 0.7650 \n",
      "____________________\n",
      "Epoch :  3\n",
      "training loss: 0.1103, acc 0.9806 \n",
      "validation loss: 0.6396, validation acc 0.8200 \n",
      "____________________\n",
      "Epoch :  4\n",
      "training loss: 0.1136, acc 0.9831 \n",
      "validation loss: 0.4283, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  5\n",
      "training loss: 0.1178, acc 0.9831 \n",
      "validation loss: 0.3163, validation acc 0.8900 \n",
      "____________________\n",
      "Epoch :  6\n",
      "training loss: 0.1205, acc 0.9831 \n",
      "validation loss: 0.2482, validation acc 0.9075 \n",
      "____________________\n",
      "Epoch :  7\n",
      "training loss: 0.1216, acc 0.9831 \n",
      "validation loss: 0.2134, validation acc 0.9300 \n",
      "____________________\n",
      "Epoch :  8\n",
      "training loss: 0.1221, acc 0.9831 \n",
      "validation loss: 0.1941, validation acc 0.9425 \n",
      "____________________\n",
      "Epoch :  9\n",
      "training loss: 0.1224, acc 0.9831 \n",
      "validation loss: 0.1826, validation acc 0.9450 \n",
      "____________________\n",
      "Epoch :  10\n",
      "training loss: 0.1227, acc 0.9831 \n",
      "validation loss: 0.1752, validation acc 0.9525 \n",
      "____________________\n",
      "Epoch :  11\n",
      "training loss: 0.1228, acc 0.9831 \n",
      "validation loss: 0.1702, validation acc 0.9550 \n",
      "____________________\n",
      "Epoch :  12\n",
      "training loss: 0.1230, acc 0.9831 \n",
      "validation loss: 0.1666, validation acc 0.9625 \n",
      "____________________\n",
      "Epoch :  13\n",
      "training loss: 0.1231, acc 0.9831 \n",
      "validation loss: 0.1639, validation acc 0.9650 \n",
      "____________________\n",
      "Epoch :  14\n",
      "training loss: 0.1232, acc 0.9831 \n",
      "validation loss: 0.1619, validation acc 0.9675 \n",
      "____________________\n",
      "Epoch :  15\n",
      "training loss: 0.1216, acc 0.9825 \n",
      "validation loss: 1.1654, validation acc 0.8100 \n",
      "____________________\n",
      "Epoch :  16\n",
      "training loss: 0.1141, acc 0.9819 \n",
      "validation loss: 1.1482, validation acc 0.8250 \n",
      "____________________\n",
      "Epoch :  17\n",
      "training loss: 0.1153, acc 0.9819 \n",
      "validation loss: 1.0123, validation acc 0.8400 \n",
      "____________________\n",
      "Epoch :  18\n",
      "training loss: 0.1180, acc 0.9831 \n",
      "validation loss: 0.9127, validation acc 0.8500 \n",
      "____________________\n",
      "Epoch :  19\n",
      "training loss: 0.1203, acc 0.9831 \n",
      "validation loss: 0.8269, validation acc 0.8550 \n",
      "____________________\n",
      "Epoch :  20\n",
      "training loss: 0.1214, acc 0.9831 \n",
      "validation loss: 0.7641, validation acc 0.8550 \n",
      "____________________\n",
      "Epoch :  21\n",
      "training loss: 0.1219, acc 0.9831 \n",
      "validation loss: 0.7190, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  22\n",
      "training loss: 0.1222, acc 0.9831 \n",
      "validation loss: 0.6859, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  23\n",
      "training loss: 0.1224, acc 0.9831 \n",
      "validation loss: 0.6610, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  24\n",
      "training loss: 0.1225, acc 0.9831 \n",
      "validation loss: 0.6418, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  25\n",
      "training loss: 0.1227, acc 0.9831 \n",
      "validation loss: 0.6268, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  26\n",
      "training loss: 0.1228, acc 0.9831 \n",
      "validation loss: 0.6149, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  27\n",
      "training loss: 0.1229, acc 0.9831 \n",
      "validation loss: 0.6054, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  28\n",
      "training loss: 0.1229, acc 0.9831 \n",
      "validation loss: 0.5975, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  29\n",
      "training loss: 0.1242, acc 0.9831 \n",
      "validation loss: 0.6136, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  30\n",
      "training loss: 0.1237, acc 0.9831 \n",
      "validation loss: 0.6063, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  31\n",
      "training loss: 0.1237, acc 0.9831 \n",
      "validation loss: 0.6009, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  32\n",
      "training loss: 0.1238, acc 0.9831 \n",
      "validation loss: 0.5964, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  33\n",
      "training loss: 0.1238, acc 0.9831 \n",
      "validation loss: 0.5926, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  34\n",
      "training loss: 0.1239, acc 0.9831 \n",
      "validation loss: 0.5893, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  35\n",
      "training loss: 0.1239, acc 0.9831 \n",
      "validation loss: 0.5865, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  36\n",
      "training loss: 0.1240, acc 0.9831 \n",
      "validation loss: 0.5840, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  37\n",
      "training loss: 0.1240, acc 0.9831 \n",
      "validation loss: 0.5819, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  38\n",
      "training loss: 0.1240, acc 0.9831 \n",
      "validation loss: 0.5800, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  39\n",
      "training loss: 0.1241, acc 0.9831 \n",
      "validation loss: 0.5783, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  40\n",
      "training loss: 0.1241, acc 0.9831 \n",
      "validation loss: 0.5768, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  41\n",
      "training loss: 0.1241, acc 0.9831 \n",
      "validation loss: 0.5755, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  42\n",
      "training loss: 0.1255, acc 0.9831 \n",
      "validation loss: 0.5722, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  43\n",
      "training loss: 0.1248, acc 0.9831 \n",
      "validation loss: 0.5708, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  44\n",
      "training loss: 0.1248, acc 0.9831 \n",
      "validation loss: 0.5696, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  45\n",
      "training loss: 0.1248, acc 0.9831 \n",
      "validation loss: 0.5686, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  46\n",
      "training loss: 0.1249, acc 0.9831 \n",
      "validation loss: 0.5677, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  47\n",
      "training loss: 0.1249, acc 0.9831 \n",
      "validation loss: 0.5669, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  48\n",
      "training loss: 0.1249, acc 0.9831 \n",
      "validation loss: 0.5662, validation acc 0.8575 \n",
      "____________________\n",
      "Epoch :  49\n",
      "training loss: 0.1249, acc 0.9831 \n",
      "validation loss: 0.5655, validation acc 0.8600 \n",
      "____________________\n",
      "Epoch :  50\n",
      "training loss: 0.1249, acc 0.9831 \n",
      "validation loss: 0.5649, validation acc 0.8600 \n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "running_loss_history = []\n",
    "epoch_list = []\n",
    "running_corrects_history = []\n",
    "val_running_loss_history = []\n",
    "val_running_corrects_history = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for seq, labels in zip(x_train, y_train):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, 200).to(device), torch.zeros(1, 1, 200).to(device))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = criterion(y_pred.view(1,-1), labels.view(1))\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.round(y_pred).argmax().to(int).squeeze(0)\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        running_loss += single_loss.item()\n",
    "\n",
    "\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in zip(x_test, y_test):\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs.view(1,-1), val_labels.view(1))\n",
    "                \n",
    "                val_preds = torch.round(val_outputs).argmax().to(int).squeeze(0)\n",
    "\n",
    "                val_running_loss += val_loss.item()\n",
    "                val_running_corrects += torch.sum(val_preds == val_labels)\n",
    "\n",
    "        \n",
    "    epoch_loss = running_loss/len(x_train)\n",
    "    epoch_acc = running_corrects.float()/ len(x_train)\n",
    "    running_loss_history.append(epoch_loss)\n",
    "    running_corrects_history.append(epoch_acc)\n",
    "\n",
    "    val_epoch_acc = val_running_corrects.float()/ len(x_test)\n",
    "    val_epoch_loss = val_running_loss/ len(x_test)\n",
    "    val_running_loss_history.append(val_epoch_loss)\n",
    "    val_running_corrects_history.append(val_epoch_acc)\n",
    "\n",
    "    epoch_list.append(i + 1)\n",
    "\n",
    "    print(\"Epoch : \",i + 1)\n",
    "    print('training loss: {:.4f}, acc {:.4f} '.format(running_loss/len(x_train), epoch_acc.item()))\n",
    "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))\n",
    "    print('_'*20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list,running_loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Loss vs Number of Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6 : Evaluating the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Predicted Values')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAFzCAYAAAAkIOMNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj80lEQVR4nO3dfbxmc7n48c+15wExnqJpjGHI4NDJ+E2kpDMlhZJImDpCMhQhSiInneokRzpJdZoiehoUenAQOVHylIdJjEqeypjGsxljxsze+/r9ca895zZm9r5n7rnvvde9Pu9e67XX+t7rXt/viv3al+t7re+KzESSJKmMugZ7AJIkSSvLQEaSJJWWgYwkSSotAxlJklRaBjKSJKm0DGQkSVJpDR/sASzP4ice8LlwaRCssdEugz0EqbK6F82KdvbX7N/aERts3tbxLosZGUmSqqq3p7ltABExLiJ+HREzI+KeiDi2aF8/Iq6JiPuKn+sV7RERZ0fEXyPiroj4fwP1YSAjSZJapRs4ITO3AXYCjoqIbYCTgGszcwJwbXEMsAcwodimAt8cqAMDGUmSqip7m9sGunzm7My8o9ifB9wLjAX2Bi4oTrsAeHexvzfwvay5GVg3Isb014eBjCRJVdXb29QWEVMj4ra6beryuoqI8cD2wC3A6MycXXz0D2B0sT8W+Hvd1x4p2pZryBb7SpKk1soGsir9fz+nAdMGOi8i1gIuAY7LzLkR/1cjnJkZEStddGxGRpIktUxEjKAWxPwwMy8tmuf0TRkVPx8r2mcB4+q+vnHRtlwGMpIkVVWTU0sDiVrq5Vzg3sw8q+6jnwMHF/sHAz+ra/9A8fTSTsCzdVNQy+TUkiRJVdXk1FIDdgYOAv4YETOKtpOB04GLI+Iw4GFg/+KzK4A9gb8CzwOHDtSBgYwkSVXVwFowzcjMG4DlLZq36zLOT+CoFenDQEaSpKpqfUam5ayRkSRJpWVGRpKkqmqgYHeoM5CRJKmiml1HZigwkJEkqarMyEiSpNLqgIyMxb6SJKm0zMhIklRVLV5Hph0MZCRJqqoOmFoykJEkqao6oNjXGhlJklRaZmQkSaoqp5YkSVJpdcDUkoGMJEkVlelTS5Ikqaw6YGrJYl9JklRaZmQkSaoqa2QkSVJpdcDUkoGMJElV5SsKJElSaXVARsZiX0mSVFpmZCRJqiqLfSVJUml1wNSSgYwkSVXVARkZa2QkSVJpmZGRJKmqOiAjYyAjSVJF+dJISZJUXmZkJElSaXXAU0sW+0qSpNIyIyNJUlU5tSRJkkqrxVNLEXEe8E7gscx8ddF2EbBVccq6wDOZOTEixgP3An8uPrs5M48cqA8DGUmSqqr1GZnzgXOA7/U1ZOYBffsR8WXg2brz78/MiSvSgYGMJElV1eKMTGb+psi0vEREBLA/8JZm+rDYV5IkDYZdgDmZeV9d22YRcWdEXB8RuzRyETMykiRVVZNTSxExFZha1zQtM6c1+PUpwPS649nAJpn5ZERMAn4aEdtm5tz+LmIgI0lSVTUZyBRBS6OByxIRMRzYF5hUd60XgBeK/dsj4n5gS+C2/q5lICNJUlUN3oJ4bwX+lJmP9DVExIbAU5nZExGbAxOABwa6kDUykiSpJSJiOnATsFVEPBIRhxUfHciLp5UA3gTcFREzgJ8AR2bmUwP1YUZGkqSqavHj15k5ZTnthyyj7RLgkhXtw0BGkqSq6oB3LRnISJJUVb6iQJIklVYHZGQs9pUkSaVlRkaSpKpyakmSJJWWgYwkSSqtzMEeQdMMZCRJqqoOyMhY7CtJkkrLjIwkSVXVARkZAxlJkqqqA9aRMZCRJKmqOiAjY42MJEkqLTMykiRVlY9fS5Kk0uqAqSUDGUmSqspARpIklVYHPLVksa8kSSotMzKSJFVU9lrsK0mSysoaGUmSVFodUCNjICNJUlV1wNSSxb6SJKm0zMhIklRV1shIkqTSMpCRJEml1QHvWrJGRpIklZYZGS3T7DmPc/LnzuTJp58mCPbbew8O2v/dTV3zZ1dcw7cuuBCAIw4+kL333I0FCxdy/Kf/g0dmzaarq4vJb3wdH/vwB1fBHUjV8/a3Teass/6dYV1dnPfd6Zzxn18f7CFpqHNqSZ1q+LBhfOKjh7PNVlswf/7z7H/YMbxhh+151WabDvjdQ44+kS+ccgJjx4xe0vbs3Hl887s/4qJzzwbggMOOYfIbd2LkyBEcOuU97DhpOxYvXsxhx3yK3970e3Z5/Q4tuzepE3V1dXH2V7/A7ntO4ZFHZnPzTVfwi8uv5t577xvsoWko64DHr1sWyETE1sDewNiiaRbw88y8t1V9atXZcIP12XCD9QFYc82Xsfmm45jz+JOMGDGCL5z1DZ5+5llWX201TjvpWDbfdNyA1/vdLbfz+h22Z521RwHw+h2253e33M6eu01mx0nbATBixAj+aastmPP4E627MalD7bjD9tx//0M8+ODfALj44p/xrr3ebiCj/nXAgngtqZGJiE8CFwIB3FpsAUyPiJNa0adaZ9bsOdx73/28Ztut+OwZZ3Pyxz7Mxed9jY8f/SE+f2Zjqes5jz/BK1+x4ZLj0Rtu8JKAZe6857j+d7fwukkTV+XwpUrYaOwr+fsjjy45fmTWbDba6JWDOCKVQm82tw0BrcrIHAZsm5mL6xsj4izgHuD0ZX0pIqYCUwG+8eXP86EPTGnR8NSo559fwMdO+TyfPOYIuqKLGX+8l+M//R9LPl+0uPaP+LL/uZofXPwzAP4261E+/PFTGTF8BGM3Gs3ZX/y3Afvp7u7hxNO+xPv3exfjxo5pzc1IktoqIs4D3gk8lpmvLtpOAw4HHi9OOzkzryg++xS1GKIHOCYzfzlQH60KZHqBjYCHl2ofU3y2TJk5DZgGsPiJB4ZGqFdhi7u7Oe6Uz/OOt72Z3SbvzHPz5zNq1JpccsFLszD7vONt7POOtwHLrpEZveEG/P7Ou5Ycz3n8CXbY/jVLjk8746tssvFGHHTAPi28I6lzPTrrH4zbeKMlxxuPHcOjj/5jEEekMsjWF/ueD5wDfG+p9q9k5pn1DRGxDXAgsC21GOJXEbFlZvb010GrHr8+Drg2Iq6MiGnFdhVwLXBsi/rUKpSZ/NsX/4vNNx3HwQfuC8Baa67J2DGv5Jf/+9sl5/zpvgcaut7Or5vEjbfewbNz5/Hs3HnceOsd7Py6SQCcPe0CnnvueU469ojW3IxUAb+/bQZbbLEZ48ePY8SIEey//9784vKrB3tYGupaPLWUmb8BnmpwNHsDF2bmC5n5IPBXYMeBvtSSjExmXhURWxYDqC/2/f1AkZWGhjvvuodfXHUtE141nvccfBQAxx5xMF/6zIl87sxz+NYF0+nu7maPXf+FrSdsPuD11ll7FEccMoUDP1SLY4889H2ss/Yo/vHY40y74EI223Qc7z30owBMec9e7Peu3Vt3c1IH6unp4djjPs0V//MjhnV1cf4FFzFz5l8Ge1ga6gav2PfoiPgAcBtwQmY+TS1euLnunEf4vxhiuSKH6Kp+Ti1Jg2ONjXYZ7CFIldW9aFa0s7/5n//Xpv7WrnXqD4+gqG0tTCvKRJaIiPHA5XU1MqOBJ4AEPgeMycwPRsQ5wM2Z+YPivHOBKzPzJ/2NwXVkJEmqqiafPKqvbV2B78zp24+IbwOXF4ezgPr1PDYu2vrlKwokSaqq3t7mtpUQEfWPpu4D3F3s/xw4MCJWi4jNgAnUlm/plxkZSZKqqsVrwUTEdGAysEFEPAJ8BpgcEROpTS09BBwBkJn3RMTFwEygGziqkbpaAxlJkqqqxcW+mbmsBeHO7ef8LwBfWJE+nFqSJEmlZUZGkqSqGiKvGWiGgYwkSRXVhpV9W85ARpKkqjIjI0mSSqsDAhmLfSVJUmmZkZEkqaoG711Lq4yBjCRJVdUBU0sGMpIkVVR2QCBjjYwkSSotMzKSJFVVB2RkDGQkSaoqF8STJEmlZUZGkiSVVgcEMhb7SpKk0jIjI0lSRWWWPyNjICNJUlV1wNSSgYwkSVVlICNJksrKlX0lSZIGkRkZSZKqqgMyMgYykiRVVfkX9jWQkSSpqqyRkSRJGkRmZCRJqqoOyMgYyEiSVFXWyEiSpLLqhBoZAxlJkqqqAzIyFvtKkqTSMiMjSVJFObUkSZLKqwOmlgxkJEmqqOyAQMYaGUmSqqq3yW0AEXFeRDwWEXfXtf1nRPwpIu6KiMsiYt2ifXxELIiIGcX2343cwoCBTES8KiJWK/YnR8QxfZ1KkiT143xg96XargFenZmvAf4CfKrus/szc2KxHdlIB41kZC4BeiJiC2AaMA74USMXlyRJQ1f2NrcNeP3M3wBPLdV2dWZ2F4c3Axs3cw+NBDK9RYf7AF/LzE8AY5rpVJIkDQFNTi1FxNSIuK1um7qCI/ggcGXd8WYRcWdEXB8RuzRygUaKfRdHxBTgYGCvom3Eio1TkiQNNc0W+2bmNGqzNSssIk4BuoEfFk2zgU0y88mImAT8NCK2zcy5/V2nkYzMocDrgS9k5oMRsRnw/ZUZtCRJUkQcArwTeH9mJkBmvpCZTxb7twP3A1sOdK0BMzKZOTMiPglsUhw/CHxppUcvSZKGhMF4/DoidgdOBP4lM5+va98QeCozeyJic2AC8MBA12vkqaW9gBnAVcXxxIj4+coNX5IkDRWtLvaNiOnATcBWEfFIRBwGnAOMAq5Z6jHrNwF3RcQM4CfAkZn51LKuW6+RGpnTgB2B6wAyc0YRKUmSpDLLaO3lM6cso/nc5Zx7CbUnpVdIQ8W+mflsxItutgPWApQkqdo6YWXfRgKZeyLifcCwiJgAHAPc2NphSZIkDayRp5Y+CmwLvABMB+YCx7VwTJIkqQ2yN5rahoJGnlp6Hjil2CRJUoeoxNRSRPwayKXbM/MtLRmRJElqi2xxsW87NFIj8/G6/dWB91BbiU+SJJVYJTIyxep69X4XEbe2aDySJEkNa2Rqaf26wy5gErBOy0YkSZLaYqgU7Dajkaml26nVyAS1KaUHgcNaOShJktR6+ZIK2PJpZGpps3YMRJIktVdHZ2QiYt/+vpiZl6764UiSJDWuv4zMXv18loCBjCRJJdbRGZnMPLSdA5EkSe1ViRoZgIh4B7XXFKze15aZ/96qQUmSpNbr6IxMn4j4b+BlwJuB7wD7Aa4jI0lSyXXCyr6NvDTyDZn5AeDpzPws8Hpgy9YOS5IkaWCNTC0tKH4+HxEbAU8CY1o3JEmS1A6VeEUBcHlErAv8J3AHtSeWvt3KQUmSpNbr7YCppf7WkbkC+BHwlcx8DrgkIi4HVs/MZ9s1QEmS1BqdXiPzLeAdwAMRcXFE7AOkQYwkSZ0he6OpbShYbiCTmT/LzCnAeOAS4APA3yLiuxGxW5vGJ0mStFwDPrWUmc9n5kWZuQ/wNmAicFWrByZJklors7ltKGhkHZnRwP7AgdSeVroYOKS1w5IkSa02VKaHmtFfse/hwBRgK2pTS5/IzBvbNTBJktRaHf3UErWF774IXJvZCU+aS5KkTtPfSyM/2M6BSJKk9uqEx68bemmkJEnqPEOlYLcZBjKSJFVUR9fIRMT6/X0xM59a9cORJEnt0ulTS7dTe69SAJsATxf76wJ/AzZr9eAkSZL609/Kvptl5ubAr4C9MnODzHw58E7g6nYNUJIktUYlFsQDdsrMw/sOMvPKiDijhWMC4MOvPbHVXUhahmc+9rrBHoKkNml1jUxEnEctAfJYZr66aFsfuIjaK5AeAvbPzKcjIoCvAnsCzwOHZOYdA/Ux4CsKgEcj4tMRMb7YTgEeXZkbkiRJQ0dmNLU14Hxg96XaTqK2Rt0E4NriGGAPYEKxTQW+2UgHjQQyU4ANgcuAS4v9KY1cXJIkDV29GU1tA8nM3wBLPxy0N3BBsX8B8O669u9lzc3AuhExZqA+BpxaKp5OOjYi1szM+QOOWpIkVUJETKWWPekzLTOnDfC10Zk5u9j/BzC62B8L/L3uvEeKttn0o5GXRr4B+A6wFrBJRGwHHJGZHxnou5Ikaehqtl63CFoGClz6+35GRFPDaGRq6SvA24Eni07/ALypmU4lSdLga/XU0nLM6ZsyKn4+VrTPAsbVnbdx0davRgIZMvPvSzX1NPI9SZI0dLWh2HdZfg4cXOwfDPysrv0DUbMT8GzdFNRyNfL49d+L6aWMiBHAscC9Kz5uSZJUJRExHZgMbBARjwCfAU4HLo6Iw4CHgf2L06+g9uj1X6k9fn1oI300EsgcSe257rHUUjxXA9bHSJJUcr0tvn5mLu8p512XcW4CR61oH40EMltl5vvrGyJiZ+B3K9qZJEkaOpLyv2upkRqZrzXYJkmSSqQ3m9uGgv7efv164A3AhhFxfN1HawPDWj0wSZLUWr0dkJHpb2ppJLW1Y4YDo+ra5wL7tXJQkiRJjVhuIJOZ1wPXR8T5mflwG8ckSZLaoCo1Mt+JiHX7DiJivYj4ZeuGJEmS2qG3yW0oaOSppQ0y85m+g+JV269o3ZAkSVI7VCUj0xsRm/QdRMSmNP96BkmSpKY1kpE5BbghIq4HAtiFF7/pUpIkldBQmR5qxoCBTGZeFRH/D9ipaDouM59o7bAkSVKrdXQgExFbZ+afiiAG4NHi5yYRsUlm3tH64UmSpFbphBqZ/jIyJwCHA19exmcJvKUlI5IkSW3RW/44pt91ZA4vfr65fcORJElqXH9TS/v298XMvHTVD0eSJLVLp7+iYK/i5yuovXPpf4vjNwM3AgYykiSVWCespdLf1NKhABFxNbBNZs4ujscA57dldJIkqWU6+qmlOuP6gpjCHGCT5Z0sSZLKoTc6e2qpz7XFu5WmF8cHAL9q3ZAkSZIa08iCeEdHxD7Am4qmaZl5WWuHJUmSWq2ja2SWcgcwLzN/FREvi4hRmTmvlQOTJEmt1Qk1MgO+NDIiDgd+AnyraBoL/LSFY5IkSW3QG81tQ0Ejb78+CtgZmAuQmfdReyRbkiRpUDUytfRCZi6KorI5IobTGdNqkiRVWicsiNdIRub6iDgZWCMidgN+DPyitcOSJEmtlk1uQ0EjgcwngceBPwJHAFcAn27loCRJUut1Qo1Mv1NLETEMuCcztwa+3Z4hSZKkduj4p5Yyswf4c0S4kq8kSRpyGin2XQ+4JyJuBeb3NWbmu1o2KkmS1HJDpc6lGY0EMqe2fBSSJKnthkqdSzOWG8hExOrAkcAW1Ap9z83M7nYNTJIktVYn1Mj0l5G5AFgM/BbYA9gGOLYdg5IkSa3X6YHMNpn5zwARcS5wa3uGJEmSOkFEbAVcVNe0OfBvwLrA4dSWdwE4OTOvWJk++gtkFvftZGZ338q+kiSpM2SL/7Rn5p+BibBkSZdZwGXAocBXMvPMZvvoL5DZLiLmFvtBbWXfucV+ZubazXYuSZIGT5unlnYF7s/Mh1dlcmS568hk5rDMXLvYRmXm8Lp9gxhJkkqut8ktIqZGxG1129R+ujsQmF53fHRE3BUR50XEeit7D428okCSJOklMnNaZr62bpu2rPMiYiTwLmrvawT4JvAqatNOs4Evr+wYGllHRpIkdaA2Loi3B3BHZs4B6PsJEBHfBi5f2QsbyEiSVFFtXBBvCnXTShExJjNnF4f7AHev7IUNZCRJqqh2FPtGxJrAbsARdc1nRMREakmhh5b6bIUYyEiSVFHtCGQycz7w8qXaDlpV17fYV5IklZYZGUmSKqoqb7+WJEkdqKPffi1Jkjpbp780UpIkdbBOmFqy2FeSJJWWGRlJkiqqtwNyMgYykiRVlDUykiSptMqfj7FGRpIklZgZGUmSKsqpJUmSVFouiCdJkkrLp5YkSVJplT+MsdhXkiSVmBkZSZIqymJfSZJUWtbISJKk0ip/GGMgI0lSZXXC1JLFvpIkqbTMyEiSVFHWyEiSpNIqfxhjICNJUmVZIyNJkjSIzMhIklRR2QGTSwYykiRVVCdMLRnISJJUUT61JEmSSqv8YYzFvpIkqcTMyKhpp9/wDRY+t4De3l56u3v5/Ls+yX6fOojt3vpaehZ189jf/sF3P/F1Fsx9frCHKg05q+13FMP+6bXkc8+y4CvHLfe8ro23YI2PfJGF08+i5483NdfpGmux+vtPoGu9Del9+nEW/vBMWDCf4RPfxIjJ7wYCFi3ghcum0Tv7oeb60pDm1JJUOHPKaTz39LwlxzNvuItLz/ghvT29vOekf2XPj+zLJaf/YBBHKA1Ni2//NYtvvJLVDjhm+SdFFyP3OIie+2as0LWHbb4twye9mRd+fM6L2kdO3oeev97FwusuY8TkfRg5eV8WXfl9ep+ew4JvnQoL5jNsq+1Zbd8jWfD1k1birlQWnVDs69SSWmLmb/9Ab0/tV+SBO//Ceq98+SCPSBqaeh+cSS6Y1+85I3bek567byKfe/bF7W/amzWOPoM1jjuLkbsd0HCfw7fdke7brwOg+/brGL7tjrWxPPxnWDAfgJ6//YVYx9/bTpdN/q8REfFQRPwxImZExG1F2/oRcU1E3Ff8XG9l76HtgUxEHNruPtVamcnHvn8qp/7iS7xpyltf8vkb3/sW7r7ujkEYmVR+sfb6DN/2dSy++Zcvah82YTu6NhjDgnNOZMFXT6Br7Kvo2mybxq651rrkvKcByHlPE2ut+5JzRuzwVnr+fGfT49fQ1tvktgLenJkTM/O1xfFJwLWZOQG4tjheKYMxtfRZ4LvL+iAipgJTAXZef3u2HrV5O8ellfSl/U7lmTlPMerla3P8D/6N2ffP4r5b7wXgHUftS09PDzf/9LeDPEqpnFbb64O8cOX3IV/8X7/DtpzIsAkTWePYLwMQI1ena4Mx9D44kzWOOh2GjyBGrk68bC26inMWXfl9ev4y46WdLH3tzV/NiB125flvntySe5KAvYHJxf4FwHXAJ1fmQi0JZCLiruV9BIxe3vcycxowDeBD4/crfwVSRTwz5ykA5j05lzt/eSubbTeB+269lzfsN5nX7DqJL7/vs4M8Qqm8ujZ+FatPOR6AWHMUw7aexAs9PUCw6LpL6b7l6pd8p6+uZXk1MvncM8So9WrZmFHrkfP/b8qq65Wbstp+H2HBeZ+D559r3Y1pSGh2Zd/6BERhWvG3/MXdwNURkcC3is9HZ+bs4vN/0E9sMJBWZWRGA28Hnl6qPYAbW9SnBsHINVYjuoIX5i9k5Bqrsc0u2/GLs3/Mtv8ykd2P2JszDvgMixYuGuxhSqX1/Jc+vGR/tfceTfefbqdn5q2w+AVGvm0K3Xf+BhYtJNZeH3p6XhSULE/3zN8zfNJkFl93GcMnTab7nlsBiHU3YPWDTmThRV8ln5g9wFXUCZot9q1PQPTjjZk5KyJeAVwTEX9a6hpZBDkrpVWBzOXAWpk5Y+kPIuK6FvWpQbD2Butw1LQTAegaNoxbf/Zb7rl+Bv9x3dcYPnIEx//gVAAeuPM+fnDKQP+uS9Wz2pSPMWzzVxNrjuJlJ3+bRddcCF3DAJaZbenTc98f6H7FxqzxkS/WGhYtZOGF/wUNBDKLrruU1d//cUbssGvx+HVt6mnkrvsTLxvFau8u/gO7t4cFXzuxqfvT0NabrZ/8yMxZxc/HIuIyYEdgTkSMyczZETEGeGxlrx/ZhptYGU4tSYPjvw7ohAcypXJa60uXRjv7O2jTfZv6W/v9h/sfb0SsCXRl5rxi/xrg34FdgScz8/SIOAlYPzNXKmp2HRlJkiqqDRmD0cBlEQG1mONHmXlVRPweuDgiDgMeBvZf2Q4MZCRJqqhWr+ybmQ8A2y2j/UlqWZmmGchIklRRzT61NBQYyEiSVFGdUBHnKwokSVJpmZGRJKmifPu1JEkqLWtkJElSaXVCjYyBjCRJFTVUF8VdERb7SpKk0jIjI0lSRVnsK0mSSssaGUmSVFqd8NSSNTKSJKm0zMhIklRR1shIkqTS6oTHrw1kJEmqKIt9JUlSaVnsK0mSNIjMyEiSVFEW+0qSpNKy2FeSJJVWJ2RkrJGRJEmlZUZGkqSK6oSnlgxkJEmqqF5rZCRJUlmVP4wxkJEkqbIs9pUkSRpEZmQkSaqoTsjIGMhIklRRLognSZJKy4yMJEkqrU5YR8ZiX0mSVFoGMpIkVVRmNrUNJCLGRcSvI2JmRNwTEccW7adFxKyImFFse67sPTi1JElSRbWhRqYbOCEz74iIUcDtEXFN8dlXMvPMZjswkJEkqaJa/dRSZs4GZhf78yLiXmDsquzDqSVJktRyETEe2B64pWg6OiLuiojzImK9lb2ugYwkSRXVSza1RcTUiLitbpu6rH4iYi3gEuC4zJwLfBN4FTCRWsbmyyt7D04tSZJUUc0+fp2Z04Bp/Z0TESOoBTE/zMxLi+/Nqfv828DlKzsGAxlJkiqqt8U1MhERwLnAvZl5Vl37mKJ+BmAf4O6V7cNARpKkimrDgng7AwcBf4yIGUXbycCUiJgIJPAQcMTKdmAgI0mSWiIzbwBiGR9dsar6MJCRJKmiWj211A4GMpIkVVQnvGvJQEaSpIoyIyNJkkqrEzIyLognSZJKy4yMJEkV5dSSJEkqrU6YWjKQkSSpojJ7B3sITbNGRpIklZYZGUmSKqrXqSVJklRWabGvJEkqKzMykiSptDohI2OxryRJKi0zMpIkVZQL4kmSpNJyQTxJklRanVAjYyAjSVJFdcJTSxb7SpKk0jIjI0lSRTm1JEmSSsunliRJUml1QkbGGhlJklRaZmQkSaqoTnhqyUBGkqSK6oSpJQMZSZIqymJfSZJUWp3wigKLfSVJUmmZkZEkqaKcWpIkSaVlsa8kSSota2QkSVJpZWZT20AiYveI+HNE/DUiTmrFPRjISJKkVS4ihgFfB/YAtgGmRMQ2q7ofp5YkSaqoFtfI7Aj8NTMfAIiIC4G9gZmrshMzMpIkVVQ2uQ1gLPD3uuNHirZVashmZL7z0E9isMeglRcRUzNz2mCPQ6oaf/e0IroXzWrqb21ETAWm1jVNa/e/f2Zk1CpTBz5FUgv4u6e2ycxpmfnauq0+iJkFjKs73rhoW6UMZCRJUiv8HpgQEZtFxEjgQODnq7qTITu1JEmSyiszuyPiaOCXwDDgvMy8Z1X3YyCjVnGOXhoc/u5pyMjMK4ArWtlHdMLyxJIkqZqskZEkSaVlIKNVqh3LUUt6qYg4LyIei4i7B3ssUjsZyGiVaddy1JKW6Xxg98EehNRuBjJalZYsR52Zi4C+5agltVhm/gZ4arDHIbWbgYxWpbYsRy1JUh8DGUmSVFoGMlqV2rIctSRJfQxktCq1ZTlqSZL6GMholcnMbqBvOep7gYtbsRy1pJeKiOnATcBWEfFIRBw22GOS2sGVfSVJUmmZkZEkSaVlICNJkkrLQEaSJJWWgYwkSSotAxlJklRaBjLSEBQR746IjIitGzj3uIh4WRN9HRIR5yzVNr54hLdrqfYZEfG65VxnvG9eltRuBjLS0DQFuKH4OZDjgJUOZJYlMx8C/gbs0tdWBFWjMvOWVdmXJDXDQEYaYiJiLeCNwGHUVkfuax8WEWdGxN0RcVdEfDQijgE2An4dEb8uznuu7jv7RcT5xf5eEXFLRNwZEb+KiNEDDGV6ff/F/oVF5uW3EXFHsb1hGffwoixPRFweEZOL/bdFxE3Fd39c3C8RcXpEzCzu7czG/x+TVGXDB3sAkl5ib+CqzPxLRDwZEZMy83ZgKjAemJiZ3RGxfmY+FRHHA2/OzCcGuO4NwE6ZmRHxIeBE4IR+zr8YmBERHy1WbT4AeC/wGLBbZi6MiAnUAp7XNnJjEbEB8GngrZk5PyI+CRwfEV8H9gG2Lsa3biPXkyQDGWnomQJ8tdi/sDi+HXgr8N9FUEFmPrWC190YuCgixgAjgQf7Ozkz5xQ1L7tGxBygOzPvjoh1gHMiYiLQA2y5AmPYCdgG+F1EUIzjJuBZYCFwbkRcDly+QncmqbIMZKQhJCLWB94C/HNEJDAMyIj4xApcpv69I6vX7X8NOCszf15M85zWwLX6ppfmFPsAHyuOt6M2Pb1wGd/r5sVT133jCOCazHxJ7U9E7AjsCuxH7Z1db2lgfJIqzhoZaWjZD/h+Zm6ameMzcxy1zMkuwDXAERExHJYEPQDzgFF115gTEf9UPHG0T137OsCsYv/gBsdzKbAntWmlC+uuMzsze4GDqAVbS3sImBgRXRExDtixaL8Z2DkitijuYc2I2LKok1knM6+gFiht1+D4JFWcgYw0tEwBLluq7ZKi/TvUniS6KyL+ALyv+HwacFVfsS9wErWpmRuB2XXXOQ34cUTcDgxUTwNAZj5DbepnTmY+UDR/Azi4GMPWwPxlfPV31AKwmcDZwB3F9R4HDgGmR8RdxbW3phaIXV603QAc38j4JMm3X0uSpNIyIyNJkkrLQEaSJJWWgYwkSSotAxlJklRaBjKSJKm0DGQkSVJpGchIkqTSMpCRJEml9f8Bd6fYcuyosNEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for inputs, labels in zip(x_test, y_test):\n",
    "\n",
    "                output = model(inputs)          \n",
    "                predictions.append(output.argmax().to(int).to('cpu').item())\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test.to('cpu').numpy(),predictions)\n",
    "cm\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe1fbfa14f7916735696a9322e667a237902258ca1fb6b99eeb22f79e9159140"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
